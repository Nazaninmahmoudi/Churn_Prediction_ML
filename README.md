# ğŸ“ˆChurn_Prediction_ML(2025)
## ğŸ“Œ Project Overview
This project aims to predict customer churn using machine learning models. The dataset contains customer behavior data from a telecom company, with various features such as customer demographics, usage patterns, and subscription details. By applying different classification models, we identify the most effective approach for predicting whether a customer will churn or remain.

## ğŸ“Š Dataset
The dataset consists of customer information like tenure, online security, contract type, and payment methods, along with their subscription status (churn or no churn). The data has been preprocessed using techniques such as scaling, encoding, and handling class imbalances to ensure optimal model performance.

## âš™ï¸ Models Used

We experimented with various classification models and fine-tuned hyperparameters to find the best-performing model:             

ğŸ”¹ Random Forest Classifier            

ğŸ”¹ Decision Tree Classifier             

ğŸ”¹ K-Nearest Neighbors (KNN)            

ğŸ”¹ XGBoost Classifier           

ğŸ”¹ LightGBM Classifier                

ğŸ”¹ Stacked Model (Best Performing Model)               

## ğŸ”® Churn Prediction 

Using machine learning models like Random Forest, XGBoost, and Stacking, we successfully built a model that predicts whether a customer will churn based on features like account age, subscription type, and usage frequency. The model was trained on historical data and fine-tuned using hyperparameter optimization.                   
The output of the model provides an accurate prediction of churn, helping businesses identify at-risk customers and take proactive steps to retain them.            

## ğŸ“ˆ Key Findings

âœ… Customer tenure has a strong negative correlation with churnâ€”longer tenures are associated with lower churn rates.              
âœ… Payment method and contract type are critical features in predicting churn behavior.                  
âœ… The stacked model provided the best performance, combining the strengths of multiple classifiers to minimize errors and avoid overfitting.             

## ğŸ“Š Results & Performance

ğŸ¯ Train Score: ~99.75%                             
ğŸ¯ Test Score: ~82.28%                   
âœ… Minimal Overfitting: While some models showed signs of overfitting (like Random Forest), models such as XGBoost and the stacked model, showed good generalization performance.                      

## ğŸ“Dataset

Kaggle Dataset URL: https://www.kaggle.com/datasets/blastchar/telco-customer-churn  

## ğŸ‘©â€ğŸ’» Author & Contact

ğŸ“Œ Project by: Nazanin Mahmoudy, 2025                              
ğŸ“§ Email: Nazaninmahmoudy@gmail.com                     
ğŸ”— GitHub: https://github.com/Nazaninmahmoudi                            
ğŸ”— Kaggle: https://www.kaggle.com/nazaninmahmoudy                              
